# Next_Word_Prediction
## Introduction
Next Word Prediction is a type of language modeling problem where the goal is to predict the next word given a sequence of words. This project explores different neural network architectures like LSTM, BiLSTM, and RNN for this task.

## Features

-Next Word Prediction using LSTM, BiLSTM, and RNN models

-Comparison of different model architectures

-Detailed preprocessing and training pipeline

-Visualization of results

## Models

### LSTM (Long Short-Term Memory)
LSTM is a type of recurrent neural network (RNN) that is capable of learning long-term dependencies. It is particularly useful in tasks where context is important.

### BiLSTM (Bidirectional LSTM)
BiLSTM is an extension of LSTM where the input sequence is fed in both forward and backward directions. This helps in capturing dependencies from both past and future context.

### RNN (Recurrent Neural Network)
RNNs are neural networks with loops that allow information to be passed from one step of the network to the next. They are commonly used in sequence prediction problems.

## Results
Include here some visualizations, metrics, or results that you obtained after training your models.

Accuracy: Include accuracy metrics
Loss: Include loss metrics
Example Predictions: Provide examples of text and their predicted next words
